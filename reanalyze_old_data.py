"""
æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¬ã‚³ãƒ¼ãƒ‰ã«æ–°ã—ã„åˆ†æã‚’é©ç”¨ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import sys
import os

# Add src directory to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'dashboard'))

import sqlite3
import json
from datetime import datetime, timedelta
from stock_analyzer import StockAnalyzer
from disclosure_fetcher import DisclosureFetcher
from earnings_analyzer import EarningsAnalyzer
from models import DB_PATH
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def reanalyze_recent_data(days: int = 7):
    """
    éå»Næ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å†åˆ†æ

    Args:
        days: ä½•æ—¥å‰ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’å†åˆ†æã™ã‚‹ã‹
    """
    logger.info(f"=== éå»{days}æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å†åˆ†æ ===\n")

    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # éå»Næ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆåˆ†æãŒã¾ã ã®ã‚‚ã®ã€ã¾ãŸã¯å¤ã„åˆ†æã®ã‚‚ã®ï¼‰
    start_date = (datetime.now() - timedelta(days=days)).isoformat()

    cursor.execute('''
        SELECT DISTINCT stock_code, stock_name, created_at
        FROM pts_ranking
        WHERE created_at >= ?
        GROUP BY stock_code, created_at
        ORDER BY created_at DESC
    ''', (start_date,))

    records = cursor.fetchall()
    logger.info(f"å†åˆ†æå¯¾è±¡: {len(records)} ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰\n")

    if not records:
        logger.info("å†åˆ†æã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        conn.close()
        return

    # Analyzers ã‚’åˆæœŸåŒ–
    stock_analyzer = StockAnalyzer()
    disclosure_fetcher = DisclosureFetcher()
    earnings_analyzer = EarningsAnalyzer()

    analyzed_count = 0
    skipped_count = 0

    for code, name, timestamp in records:
        try:
            # ãã®æ™‚ç‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            cursor.execute('''
                SELECT stock_code, stock_name, pts_price, change_rate, change_amount,
                       volume, market, company_info, news, main_reason, analysis
                FROM pts_ranking
                WHERE stock_code = ? AND created_at = ?
            ''', (code, timestamp))

            row = cursor.fetchone()
            if not row:
                continue

            # æ—¢ã«åˆ†ææ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
            existing_analysis = json.loads(row[10]) if row[10] and row[10] != '{}' else {}
            if existing_analysis.get('earnings_detail'):
                logger.info(f"[SKIP] {code} {name} - æ—¢ã«æ±ºç®—åˆ†ææ¸ˆã¿")
                skipped_count += 1
                continue

            logger.info(f"[åˆ†æä¸­] {code} {name} ({timestamp[:10]})")

            # æ ªå¼æƒ…å ±ã‚’å†æ§‹ç¯‰
            stock = {
                'code': row[0],
                'name': row[1],
                'pts_price': row[2],
                'change_rate': row[3],
                'change_amount': row[4],
                'volume': row[5],
                'market': row[6],
            }

            # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—
            news = json.loads(row[8]) if row[8] else []

            # é–‹ç¤ºæƒ…å ±ã‚’å–å¾—
            disclosure_info = disclosure_fetcher.fetch_disclosure_info(code)
            earnings_detail = None

            # æ±ºç®—ãŒã‚ã‚‹å ´åˆã¯è©³ç´°åˆ†æ
            if disclosure_info.get('has_earnings'):
                logger.info(f"  â†’ æ±ºç®—ç™ºè¡¨ã‚ã‚Šã€Claude APIã§åˆ†æä¸­...")
                disclosure_title = disclosure_info['disclosures'][0]['title'] if disclosure_info['disclosures'] else disclosure_info['earnings_summary']

                earnings_detail = earnings_analyzer.analyze_earnings_detail(
                    disclosure_title,
                    news,
                    stock
                )

                # æ±ºç®—æƒ…å ±ã‚’ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«è¿½åŠ 
                if earnings_detail and earnings_detail.get('earnings_reason'):
                    earnings_news = {
                        'title': f"ã€æ±ºç®—ã€‘{disclosure_info['earnings_summary']} - {earnings_detail['earnings_reason']}",
                        'date': disclosure_info['disclosures'][0]['date'] if disclosure_info['disclosures'] else '',
                        'url': disclosure_info['disclosures'][0]['url'] if disclosure_info['disclosures'] else '',
                        'source': 'é–‹ç¤ºæƒ…å ±ï¼ˆå†åˆ†æï¼‰'
                    }
                    news.insert(0, earnings_news)

            # ä¸Šæ˜‡ç†ç”±ã¨å°†æ¥æ€§ã‚’å†åˆ†æ
            analysis = stock_analyzer.analyze_price_increase_reason(news, stock)

            # æ±ºç®—ã®è©³ç´°åˆ†æã‚’è¿½åŠ 
            if earnings_detail:
                analysis['earnings_detail'] = earnings_detail

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ›´æ–°
            cursor.execute('''
                UPDATE pts_ranking
                SET main_reason = ?,
                    analysis = ?,
                    future_potential = ?,
                    news = ?
                WHERE stock_code = ? AND created_at = ?
            ''', (
                analysis.get('main_reason', ''),
                json.dumps(analysis, ensure_ascii=False),
                analysis.get('future_potential', ''),
                json.dumps(news, ensure_ascii=False),
                code,
                timestamp
            ))

            conn.commit()
            analyzed_count += 1

            if earnings_detail:
                logger.info(f"  âœ“ æ±ºç®—åˆ†æã‚’è¿½åŠ : {earnings_detail.get('earnings_reason', '')[:50]}...")
            else:
                logger.info(f"  âœ“ åˆ†æã‚’æ›´æ–°")

        except Exception as e:
            logger.error(f"  âœ— ã‚¨ãƒ©ãƒ¼: {e}")
            continue

    # Cleanup
    disclosure_fetcher.close()

    conn.close()

    logger.info(f"\n=== å®Œäº† ===")
    logger.info(f"åˆ†ææ¸ˆã¿: {analyzed_count} ä»¶")
    logger.info(f"ã‚¹ã‚­ãƒƒãƒ—: {skipped_count} ä»¶")


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å†åˆ†æ')
    parser.add_argument('--days', type=int, default=7, help='ä½•æ—¥å‰ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’å†åˆ†æã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 7æ—¥ï¼‰')
    args = parser.parse_args()

    print(f"ğŸ”„ éå»{args.days}æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å†åˆ†æã—ã¾ã™\n")
    print("âš ï¸  Claude APIè¨­å®šãŒãªã„å ´åˆã¯ç°¡æ˜“åˆ†æã®ã¿è¡Œã‚ã‚Œã¾ã™")
    print("   è©³ç´°ã¯ CLAUDE_API_SETUP.md ã‚’å‚ç…§\n")

    confirm = input("ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/n): ")
    if confirm.lower() == 'y':
        reanalyze_recent_data(args.days)
    else:
        print("ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
